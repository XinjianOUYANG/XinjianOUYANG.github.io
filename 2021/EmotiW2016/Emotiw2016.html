<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
   
    <h1>
        <b>EmotiW2016</b>: Video-Based Emotion Recognition using CNN-RNN and C3D Hybrid Networks
    </h1>

    <p>
        <b>Abstract</b>: 
        The paper presents a "Video-Based Emotion Recognition using CNN-RNN and C3D Hybrid Networks", 
        whose core module is a hybrid network that combines recurrent neural network(RNN) and 3D convolutional networks(C3D) in a late-fusion fashion. 
        The architecture of this network is shown as following: 
    </p>
    <div>
        <a class="image fit"><img src="/2021/EmotiW2016/NN_structure.jpg" width="90%" height="90%" /></a>
    </div>

    <p>
        <b>Keywords:</b> Emotion Recognition; RNN; LSTM network; C3D; Model Fusion
    </p>

    <p>
        <b>limitations of traditional CNNs:</b>
        Traditional convolutional neural networks have a major limitation that they just handle spatial information. 
        For example, in the EmotiW2014 winner’s work, all video frames are extracted from videos and regarded as the static images for further process. 
        The aggregating image features of each video form a feature vector which neglects the important temporal video information.
        (即CNN只能提取暂态特征，整体与局部)
        <a class="post-title-link" href="https://blog.csdn.net/lrglgy/article/details/88764906" >
            <span >The advantages and limitations of CNN</span>
        </a>
    </p>

    <p>
        <b>Deep 3-dimensional convolutional networks (C3D):</b>
        C3D can model appearance and motion information simultaneously 
        and the C3D features with a linear classifier can achieve good performance 
        on different video analysis benchmarks. 
        It is found that C3D networks have a good performance in emotion recognition
    </p>
     <b>2D ConvNets v.s. 3D ConvNets</b>
        in our 3D ConvNets, the operations are performed spatio-temporally by adding an additional time dimension.
        Hence such C3D networks preserve the temporal information of the input signals, 
        resulting in a more distinctive result. 
    <p>
        C3D can be understood as a 3D convolution on three channels. 
        In such way, the results of C3D transform can be used as features for many tasks.
        <a class="image fit"><img src="/2021/EmotiW2016/C2D_C3D.jpg" width="50%" height="50%" /></a>
    </p>

    <p>
        The main contribution of this paper: hybrid <b>CNN-RNN</b> + C3D
    </p>

    <p>
        <b>Long Short-Term Memory(LSTM):</b>
        LSTM is a CNN-features-based spatio-tempral RNN model, which is widely adopted. 
        LSTM has memory ability and suits for processing sequences with contexts well. 
    </p>
    <p>   
        An encoder LSTM can be used to map an input sequence into a fixed length vector representation. 
        This vector representation is decoded using single decoder LSTM or multiple decoder LSTMs 
        to handle different tasks such as emotion classification. 
        Recently, LSTMs are also well developed and shown to be efficient to deal with various sequences versus sequences problems, 
        such as audio analysis, video captioning, video action recognition, and so on.
    </p>
    
    <p>
        Although RNNs have been widely used in many tasks such as handwriting recognition or speech recognition, 
        they have difficulties in learning long-term dependencies due to <b>the vanishing and exploding gradient problem</b>. 
        A Long Short Term Memory (LSTM) network is a special kind of RNN 
        which is capable of addressing this long-term dependencies.

        <a class="post-title-link" href="https://en.wikipedia.org/wiki/Long_short-term_memory" >
            <span >Mathematical details of LTSM</span>
        </a>
    </p>
    <div> 
        <p>The Long Short-Term Memory (LSTM) cell can process data sequentially and keep its hidden state through time.</p>
        <a class="image fit"><img src="/2021/EmotiW2016/The_LSTM_Cell.svg.png" width="40%" height="40%" /></a>
        <p>A simple LSTM block with only input, output, and forget gates(GRUs)</p>
        <a class="image fit"><img src="/2021/EmotiW2016/1920px-Peephole_Long_Short-Term_Memory.svg.png" width="40%" height="40%" />
        </a>
    </div>

    <p>Reference:</p>
    <li>
        <a class="post-title-link" href="/2021/EmotiW2016/Video-Based Emotion Recognition using CNN-RNN and C3D Hybrid Networks.pdf" >
            <span >Paper: Video-Based Emotion Recognition using CNN-RNN and C3D Hybrid Networks</span>
        </a>
    </li>
    <li>
        <a class="post-title-link" href="/2021/EmotiW2016/EmotiW 2016 Video and Group-Level Emotion Recognition Challenges.pdf" >
            <span >PDF: Introduction of EmotiW 2016 Video and Group-Level Emotion Recognition Challenges</span>
        </a>
    </li>
    <li>
        <a class="post-title-link" href="https://github.com/lidian007/EmotiW2016" >
            <span >Github source code</span>
        </a>
    </li>

</body>
</html>